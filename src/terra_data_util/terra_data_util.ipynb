{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that a recent version of firecloud is installed.\n",
    "The version must be 0.16.23 or later for flexible entity support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade firecloud\n",
    "# ! pip show firecloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from firecloud import fiss\n",
    "import firecloud.api as fapi\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen3 Data Model Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "GEN3_GENO_PHENO_MERGE_SPEC = [\n",
    "    {\n",
    "        \"join_key\": \"simple_germline_variation\",\n",
    "        \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"submitted_aligned_reads\",\n",
    "        \"table_names\": [\"submitted_aligned_reads\", \"aligned_reads_index\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"read_group\",\n",
    "        \"table_names\": [\"read_group\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"aliquot\",\n",
    "        \"table_names\": [\"aliquot\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"sample\",\n",
    "        \"table_names\": [\"sample\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"subject\",\n",
    "        \"table_names\": [\"subject\", \"blood_pressure_test\", \"demographic\", \"exposure\", \"lab_result\", \"medical_history\", \"medication\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"study\",\n",
    "        \"table_names\": [\"study\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"project\",\n",
    "        \"table_names\": [\"project\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"program\",\n",
    "        \"table_names\": [\"program\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "GEN3_ENTITY_ID_COLUMN = \"subject_submitter_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_gen3_geno_pheno_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_GENO_PHENO_MERGE_SPEC, new_table_name, GEN3_ENTITY_ID_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN3_GENO_MERGE_SPEC = [\n",
    "    {\n",
    "        \"join_key\": \"simple_germline_variation\",\n",
    "        \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"submitted_aligned_reads\",\n",
    "        \"table_names\": [\"submitted_aligned_reads\", \"aligned_reads_index\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"read_group\",\n",
    "        \"table_names\": [\"read_group\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"aliquot\",\n",
    "        \"table_names\": [\"aliquot\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"sample\",\n",
    "        \"table_names\": [\"sample\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"subject\",\n",
    "        \"table_names\": [\"subject\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"study\",\n",
    "        \"table_names\": [\"study\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"project\",\n",
    "        \"table_names\": [\"project\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"program\",\n",
    "        \"table_names\": [\"program\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "GEN3_ENTITY_ID_COLUMN = \"subject_submitter_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_gen3_geno_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_GENO_MERGE_SPEC, new_table_name, GEN3_ENTITY_ID_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of tables defined in the Gen3 data model, for Notebook-internal use.\n",
    "# All of the tables used in merge specications must exist in this list,\n",
    "# yet this list may contain additional tables are not used in the\n",
    "# merge specifications and do not exist in the current workspace data table.\n",
    "#\n",
    "# The following information could(/should) be obtained from Gen3 (dynamically?).\n",
    "# For now, use an explicit list.\n",
    "\n",
    "GEN3_TABLE_NAMES={'aligned_reads_index',\n",
    " 'aliquot',\n",
    " 'blood_pressure_test',\n",
    " 'demographic',\n",
    " 'exposure',\n",
    " 'germline_variation_index',\n",
    " 'lab_result',\n",
    " 'medical_history',\n",
    " 'medication',\n",
    " 'program',\n",
    " 'project',                \n",
    " 'read_group',\n",
    " 'reference_file',\n",
    " 'sample',\n",
    " 'simple_germline_variation',\n",
    " 'subject',\n",
    " 'submitted_aligned_reads',\n",
    " 'study'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_terra_table(merge_spec: list, entity_name: str, entity_id_column:str)  -> pd.DataFrame:\n",
    "    consolidated_df = consolidate_to_df(merge_spec)\n",
    " \n",
    "    # Add \"entity:{entity_name}_id\" as the first column, as required by Terra.\n",
    "    # TODO Check if there is a better way to do this.\n",
    "    consolidated_df.insert(0, f\"entity:{entity_name}_id\", consolidated_df[entity_id_column])\n",
    "    print(\"The consolidated data frame size is: {} rows x {} columns\".format(consolidated_df.shape[0], consolidated_df.shape[1]))\n",
    "    columns = consolidated_df.columns.tolist()\n",
    "    write_df_to_tsv_file(consolidated_df, \"consolidated_df\")\n",
    "    consolidated_tsv = consolidated_df.to_csv(sep=\"\\t\", index=False)\n",
    "    fiss_entity_import(BILLING_PROJECT_ID, WORKSPACE, consolidated_tsv, \"flexible\")\n",
    "    \n",
    "    # Outout the resulting data table size TODO - Find a more efficient way to do this\n",
    "    data_table_df = get_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, entity_name)\n",
    "    print(\"The consolidated data table \"\"{}\"\" size is: {} rows x {} columns\".format(entity_name, data_table_df.shape[0], data_table_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_tsv(merge_spec: list)  -> pd.DataFrame:\n",
    "    return consolidate_to_df(merge_spec).to_csv(sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_df(merge_spec: list)  -> pd.DataFrame:\n",
    "    merged_df = None\n",
    "    for merge_info in merge_spec:\n",
    "        join_key = get_eid_column_name(merge_info['join_key'])\n",
    "        merged_df = consolidate_tables_to_df(join_key, merge_info['table_names'], merged_df)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_tables_to_df(common_key: str, table_names: list, initial_df = None) -> pd.DataFrame:\n",
    "    if initial_df is None:\n",
    "        assert len(table_names) >= 2, \"At least two table names are required.\" \n",
    "        table_name = table_names[0]\n",
    "        merged_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        if table_name == \"sample\":\n",
    "            merged_df = deduplicate_sample_data(merged_df)\n",
    "        table_names = table_names[1:]\n",
    "    else:\n",
    "        assert len(table_names) >= 1, \"At least one table names is required to merge with previous data.\"\n",
    "        merged_df = initial_df\n",
    "    for table_name in table_names:\n",
    "        current_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        if table_name == \"sample\":\n",
    "            current_df = deduplicate_sample_data(current_df)\n",
    "        # DEBUG -- Comment out the following two lines before committing\n",
    "        # write_df_to_tsv_file(merged_df, \"merged_df\")\n",
    "        # write_df_to_tsv_file(current_df, \"current_df\")\n",
    "        merged_df = merged_df.merge(current_df, on=common_key, how=\"inner\", copy=False, suffixes=(False, False))\n",
    "        # Deduplicate \"*_eid\" columns\n",
    "        merged_df = merged_df.loc[:,~merged_df.columns.duplicated()]\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gen3_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = get_terra_table_to_df(project, workspace, table_name)\n",
    "    columns = table_df.columns\n",
    "    rename_column(table_df, f\"entity:{table_name}_id\", f\"{table_name}_eid\") # Column 0\n",
    "    for column in columns[1:]:\n",
    "        if column in GEN3_TABLE_NAMES:\n",
    "            rename_column(table_df, column, f\"{column}_eid\")\n",
    "        else:\n",
    "            rename_column(table_df, column, f\"{table_name}_{column}\")\n",
    "    # Deduplicate \"*_eid\" columns\n",
    "    table_df = table_df.loc[:,~table_df.columns.duplicated()]\n",
    "    return table_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_eid_column_name(entity_type: str):\n",
    "    return f\"{entity_type}_eid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_sample_data(df: pd.DataFrame)  -> pd.DataFrame:\n",
    "    # Some TOPMed projects (COPDGene, MESA, maybe others) are known to have multiple sample\n",
    "    # entries for the same subject. According to BDC data experts, the duplicates should\n",
    "    # be equivalent, so just keep the first entry found in each case.\n",
    "    deduped_df = df.drop_duplicates(subset=[\"subject_eid\"], keep=\"first\", inplace=False)\n",
    "    original_row_count = df.shape[0]\n",
    "    deduped_row_count = deduped_df.shape[0]\n",
    "    if deduped_row_count < original_row_count:\n",
    "        difference = original_row_count - deduped_row_count\n",
    "        print(\"Removed {} duplicate rows from \\\"sample\\\" data based on subject. Retained the first entry found.\".format(difference))\n",
    "    else:\n",
    "        print(\"No duplicate samples identified.\")\n",
    "    return deduped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common/General Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = pd.read_csv(io.StringIO(fapi.get_entities_tsv(project, workspace, table_name, model=model).text), sep='\\t')\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rename_column(df: pd.DataFrame, current_column_name: str, new_column_name: str) -> None:\n",
    "    df.rename(columns={current_column_name : new_column_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_df_to_tsv_file(df: pd.DataFrame, filename: str) -> None:\n",
    "    filename += \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S%f\") + \".tsv\"\n",
    "    with open(filename, mode=\"w\") as tsv_file:\n",
    "        tsv_string = df.to_csv(sep=\"\\t\", index=False)\n",
    "        tsv_file.write(tsv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fiss_entity_import(project: str, workspace: str, entity_tsv: str, model: str):\n",
    "    response = fapi.upload_entities(project, workspace, entity_tsv, model)\n",
    "    fapi._check_response_code(response, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def delete_terra_table(project: str, workspace: str, table_name: str):\n",
    "    # TODO There has to be better way than this to simply delete a table/entity-type.\n",
    "    table_to_delete_df = get_terra_table_to_df(project, workspace, table_name)\n",
    "    entity_id_column_name = f\"entity:{table_name}_id\"\n",
    "    entity_id_series = table_to_delete_df[entity_id_column_name]\n",
    "    num_chunks = entity_id_series.size / 100\n",
    "    for chunk in  np.array_split(entity_id_series, num_chunks):\n",
    "        response = fapi.delete_entity_type(project, workspace, table_name, chunk)\n",
    "        fapi._check_response_code(response, 204)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Test/Demo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WORKSPACE_NAMESPACE']=\"anvil-stage-demo\"\n",
    "os.environ['GOOGLE_PROJECT']=os.environ['WORKSPACE_NAMESPACE']\n",
    "# os.environ['WORKSPACE_NAME']=\"mbaumann dev fiss debug playground 20190925 2141\"\n",
    "os.environ['WORKSPACE_NAME']=\"mbaumann terra_data_util test MESA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and verify the Google billing project environment variable\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "BILLING_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and verify the Workspace name\n",
    "WORKSPACE = os.environ['WORKSPACE_NAME']\n",
    "WORKSPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify which example tables to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_example_consolidated_geno_pheno_table=False\n",
    "create_example_consolidated_geno_table=True\n",
    "create_example_consolidated_pheno_table=True\n",
    "create_example_consolidated_custom_table=True\n",
    "delete_created_tables=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to create each table specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_example_consolidated_geno_pheno_table:\n",
    "    example_table_name = \"example_consolidated_geno_pheno_table\"\n",
    "    consolidate_gen3_geno_pheno_tables(example_table_name)\n",
    "    if delete_created_tables:\n",
    "         delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_example_consolidated_geno_table:\n",
    "    example_table_name = \"example_consolidated_geno_table\"\n",
    "    consolidate_gen3_geno_tables(example_table_name)\n",
    "    if delete_created_tables:\n",
    "         delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
