{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from firecloud import fiss\n",
    "import firecloud.api as fapi\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen3 High-Level Configuration and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# The following information could(/should) be obtained from Gen3 (dynamically?).\n",
    "# For now, use an explicit list.\n",
    "GEN3_TABLE_NAMES={'aligned_reads_index',\n",
    " 'aliquot',\n",
    " 'blood_pressure_test',\n",
    " 'case',\n",
    " 'demographic',\n",
    " 'exposure',\n",
    " 'germline_variation_index',\n",
    " 'lab_result',\n",
    " 'medical_history',\n",
    " 'medication',\n",
    " 'read_group',\n",
    " 'sample',\n",
    " 'simple_germline_variation',\n",
    " 'submitted_aligned_reads'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "GEN3_GENO_PHENO_MERGE_SPEC = [\n",
    "    {\n",
    "        \"join_key\": \"simple_germline_variation\",\n",
    "        \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"submitted_aligned_reads\",\n",
    "        \"table_names\": [\"submitted_aligned_reads\", \"aligned_reads_index\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"read_group\",\n",
    "        \"table_names\": [\"read_group\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"aliquot\",\n",
    "        \"table_names\": [\"aliquot\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"sample\",\n",
    "        \"table_names\": [\"sample\"]\n",
    "    },\n",
    "    {\n",
    "        \"join_key\": \"case\",\n",
    "        \"table_names\": [\"case\", \"blood_pressure_test\", \"demographic\", \"exposure\", \"lab_result\", \"medical_history\", \"medication\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "GEN3_ENTITY_ID_COLUMN = \"case_submitter_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_gen3_geno_pheno_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_GENO_PHENO_MERGE_SPEC, new_table_name, GEN3_ENTITY_ID_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# action values: replace, update\n",
    "def consolidate_gen3_geno_tables(new_table_name: str, action:str =\"replace\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Mid-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_terra_table(merge_spec: list, entity_name: str, entity_id_column:str)  -> pd.DataFrame:\n",
    "    consolidated_df = consolidate_to_df(merge_spec)\n",
    "    # Add \"entity:{entity_name}_id\" as the first column, as required by Terra.\n",
    "    # TODO Check if there is a better way to do this.\n",
    "    consolidated_df.insert(0, f\"entity:{entity_name}_id\", consolidated_df[entity_id_column])\n",
    "    columns = consolidated_df.columns.tolist()\n",
    "    write_df_to_tsv_file(consolidated_df, \"consolidated_df\")\n",
    "    consolidated_tsv = consolidated_df.to_csv(sep=\"\\t\", index=False)\n",
    "    fiss_entity_import(BILLING_PROJECT_ID, WORKSPACE, consolidated_tsv, \"flexible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_tsv(merge_spec: list)  -> pd.DataFrame:\n",
    "    return consolidate_to_df(merge_spec).to_csv(sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_df(merge_spec: list)  -> pd.DataFrame:\n",
    "    merged_df = None\n",
    "    for merge_info in merge_spec:\n",
    "        join_key = get_eid_column_name(merge_info['join_key'])\n",
    "        merged_df = consolidate_tables_to_df(join_key, merge_info['table_names'], merged_df)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Lower-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_tables_to_terra_table(common_key: str, table_names: list, new_entity_type: str, entity_id_column:str) -> None:\n",
    "    consolidated_df = consolidate_tables_to_df(common_key, table_names)\n",
    "    # Add \"entity:{new_entity_type}_id\" column, as required by Terra\n",
    "    consolidated_df[f\"entity:{new_entity_type}_id\"] = consolidated_df[entity_id_column]\n",
    "    consolidated_tsv = consolidated_df.to_csv(sep=\"\\t\")\n",
    "    fiss_entity_import(BILLING_PROJECT_ID, WORKSPACE, consolidated_tsv, \"flexible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_tables_to_tsv(common_key: str, table_names: list) -> str:\n",
    "    return consolidate_tables_to_df(common_key, table_names).to_csv(sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_tables_to_df(common_key: str, table_names: list, initial_df = None) -> pd.DataFrame:\n",
    "    if initial_df is None:\n",
    "        assert len(table_names) >= 2, \"At least two table names are required.\" \n",
    "        table_name = table_names[0]\n",
    "        merged_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        table_names = table_names[1:]\n",
    "    else:\n",
    "        assert len(table_names) >= 1, \"At least one table names is required to merge with previous data.\"\n",
    "        merged_df = initial_df\n",
    "    for table_name in table_names:\n",
    "        current_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        # DEBUG -- Comment out the following two lines before committing\n",
    "        # write_df_to_tsv_file(merged_df, \"merged_df\")\n",
    "        # write_df_to_tsv_file(current_df, \"current_df\")\n",
    "        merged_df = merged_df.merge(current_df, on=common_key, how=\"inner\", copy=False, suffixes=(False, False))\n",
    "        # Deduplicate \"*_eid\" columns\n",
    "        merged_df = merged_df.loc[:,~merged_df.columns.duplicated()]\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def get_eid_column_name(entity_type: str):\n",
    "    return f\"{entity_type}_eid\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Low-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rename_column(df: pd.DataFrame, current_column_name: str, new_column_name: str) -> None:\n",
    "    df.rename(columns={current_column_name : new_column_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# FISS entity_import expects the TSV content to be in a file, yet here it is already\n",
    "# a string and it doesn't make sense to write content to a file only to read it in again.\n",
    "# The data may be large, and FISS entity_import performs chunking, which should be used.\n",
    "# Therefore bypass fiss `entity_import` per se and call `_batch_load` directly.\n",
    "# EntityImportArgs = namedtuple(\"EntityImportArgs\", [\"project\", \"workspace\", \"tsvfile\", \"chunk_size\", \"model\"])\n",
    "def fiss_entity_import_batch_bad(project: str, workspace: str, entity_tsv: str, model: str):\n",
    "    # args = EntityImportArgs(project, workspace, io.StringIO(entity_data), 500, model)\n",
    "    # fiss.entity_import(args)\n",
    "    entity_tsv_filelike = io.StringIO(entity_tsv)\n",
    "    headerline = entity_tsv_filelike.readline().strip()\n",
    "    entity_data = [l.rstrip('\\n') for l in entity_tsv_filelike]\n",
    "    return fiss._batch_load(project, workspace, headerline, entity_data, 500, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fiss_entity_import(project: str, workspace: str, entity_tsv: str, model: str):\n",
    "    response = fapi.upload_entities(project, workspace, entity_tsv, model)\n",
    "    fapi._check_response_code(response, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def get_gen3_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = get_terra_table_to_df(project, workspace, table_name)\n",
    "    columns = table_df.columns\n",
    "    rename_column(table_df, f\"entity:{table_name}_id\", f\"{table_name}_eid\") # Column 0\n",
    "    for column in columns[1:]:\n",
    "        if column in GEN3_TABLE_NAMES:\n",
    "            rename_column(table_df, column, f\"{column}_eid\")\n",
    "        else:\n",
    "            rename_column(table_df, column, f\"{table_name}_{column}\")\n",
    "    # Deduplicate \"*_eid\" columns\n",
    "    table_df = table_df.loc[:,~table_df.columns.duplicated()]\n",
    "    return table_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = pd.read_csv(io.StringIO(fapi.get_entities_tsv(project, workspace, table_name, model=model).text), sep='\\t')\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def delete_terra_table(project: str, workspace: str, table_name: str):\n",
    "    # TODO There has to be better way than this to simply delete a table/entity-type.\n",
    "    table_to_delete_df = get_terra_table_to_df(project, workspace, table_name)\n",
    "    entity_id_column_name = f\"entity:{table_name}_id\"\n",
    "    entity_id_series = table_to_delete_df[entity_id_column_name]\n",
    "    num_chunks = entity_id_series.size / 200\n",
    "    for chunk in  np.array_split(entity_id_series, num_chunks):\n",
    "        response = fapi.delete_entity_type(project, workspace, table_name, chunk)\n",
    "        fapi._check_response_code(response, 204)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def write_df_to_tsv_file(df: pd.DataFrame, filename: str) -> None:\n",
    "    filename += \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S%f\") + \".tsv\"\n",
    "    with open(filename, mode=\"w\") as tsv_file:\n",
    "        tsv_string = df.to_csv(sep=\"\\t\", index=False)\n",
    "        tsv_file.write(tsv_string)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Test/Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# Temporary settings for running in PyCharm\n",
    "os.environ['WORKSPACE_NAMESPACE']=\"anvil-stage-demo\"\n",
    "os.environ['GOOGLE_PROJECT']=os.environ['WORKSPACE_NAMESPACE']\n",
    "# os.environ['WORKSPACE_NAME']=\"mbaumann dev fiss debug playground 20190925 2141\"\n",
    "os.environ['WORKSPACE_NAME']=\"mbaumann_merge_test_amish_20191010\"\n",
    "os.environ['WORKSPACE_BUCKET']=\"gs://fc-secure-55824595-dc0f-4b14-b5fb-9d7f9cf662be\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'anvil-stage-demo'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 98
    }
   ],
   "source": [
    "# Set and verify the Google billing project environment variable\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "BILLING_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'mbaumann_merge_test_amish_20191010'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 99
    }
   ],
   "source": [
    "# Set and verify the Workspace name\n",
    "WORKSPACE = os.environ['WORKSPACE_NAME']\n",
    "WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# %%pixie_debugger\n",
    "\n",
    "consolidated_table_name = \"my_consolidated_table_all\"\n",
    "consolidate_gen3_geno_pheno_tables(consolidated_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, \"my_consolidated_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# for table_name in GEN3_TABLE_NAMES:\n",
    "#     delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, table_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}