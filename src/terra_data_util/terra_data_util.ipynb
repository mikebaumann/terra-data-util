{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen3/Terra Data Utility Functions <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version:**  \n",
    "**Status:** This is Notebook is currently a **work in progress** and is not ready for general availability/use quite yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This Notebook combines multiple Gen3 graph-structured data tables to create a single consolidated table that is easier to use.\n",
    "\n",
    "The default behavior is to produce a table keyed by subject id, with one row per subject, for all subjects in a Terra Workspace. This table may include the genomic data, harmonized clinical metadata, or both, along with the associated administrative information.\n",
    "The content of the consolidated table produced is configurable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements and Assumptions\n",
    "\n",
    "**Run in Terra**  \n",
    "This Notebook is intended to be used within the Terra Notebook environment using a Python 3 Jupyter kernel. \n",
    "\n",
    "**Workspace Data**   \n",
    "The consolidation is performed for all Gen3 data for the BioData Catalyst program in a Terra workspace. The data may be for subjects from one or more projects/cohorts.\n",
    "\n",
    "**Libraries**   \n",
    "The following libraries are expected to be available in the Terra Notebook environment, either by being preinstalled the 'Terra Notebook Runtime, Container Image, or explicit installation by the user:\n",
    "* `fiss` (version 0.16.23 or later)\n",
    "* `numpy` (version 1.15.2 or later)\n",
    "* `pandas` (0.25.3 or laster)\n",
    "\n",
    "**Global Variable Settings**\n",
    "Currently, the following global variables are required to be set prior to calling the functions in this Notebook:\n",
    "* `BILLING_PROJECT_ID`\n",
    "* `WORKSPACE` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use\n",
    "\n",
    "The recommended way to use this Notebook is to \"import\" this Notebook into a user's primary Notebook using the `%run` command. The following steps added to a user's primary Notebook is sufficient to create a consolidated data table, in this example, a consolidated table containing both the genomic data and harmonized metadata:\n",
    "\n",
    "````\n",
    "%run terra_data_util.ipynb  \n",
    "\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']  \n",
    "WORKSPACE = os.environ['WORKSPACE_NAME'\n",
    "\n",
    "consolidate_gen3_geno_pheno_tables(\"consolidated_metadata\")\n",
    "```\n",
    "\n",
    "This Notebook provides the following ready-to-use functions for creating consolidated tables:\n",
    "* `consolidate_gen3_geno_pheno_tables(new_table_name: str)`\n",
    "* `consolidate_gen3_geno_tables(new_table_name: str)`\n",
    "* `consolidate_gen3_pheno_tables(new_table_name: str)`\n",
    "\n",
    "A convenience function to delete Terra data tables, a time-consuming process, is also included:\n",
    "* `delete_terra_table(project: str, workspace: str, table_name: str)`\n",
    "\n",
    "The Terra data tables that are included in the consolidated table, and how they are combined, is defined by a merge specification defined as a Python dictionary.\n",
    "The merge specification supports standard SQL-style join operations and can be customized as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it Works\n",
    "\n",
    "This Notebook uses the Broad FireCloud API to read each Terra data table identified in the merge specification into a Pandas DataFrame and performs SQL-style joins on the tables using the Pandas `merge` operation to produce a single, consolidated table.\n",
    "References in the Gen3 data model are only the direction of the graph leaf/bottom nodes to the root/top node.\n",
    "\n",
    "During this consolidation process, the name of each column in a table is prefixed with the name of the table it is from. Additionally, the columns containing entity ids have the `_entity_id` suffix appended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that a recent version of firecloud is installed.\n",
    "The version must be 0.16.23 or later for flexible entity support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade firecloud\n",
    "# ! pip show firecloud\n",
    "# ! pip install pysnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from firecloud import fiss\n",
    "from firecloud.errors import FireCloudServerError\n",
    "import firecloud.api as fapi\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import INFO, DEBUG\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commonly Used Merge Specifications and Convenience Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a consolidated data table containing both genomic and phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN3_GENO_PHENO_MERGE_SPEC = {\n",
    "  \"default_join_type\": \"outer\",\n",
    "  \"merge_sequence\": [\n",
    "    {\n",
    "      \"join_column\": \"simple_germline_variation\",\n",
    "      \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"submitted_aligned_reads\",\n",
    "      \"table_names\": [\"submitted_aligned_reads\", \"aligned_reads_index\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"read_group\",\n",
    "      \"table_names\": [\"read_group\", \"submitted_unaligned_reads\", \"read_group_qc\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"aliquot\",\n",
    "      \"table_names\": [\"aliquot\", \"submitted_cnv_array\", \"submitted_snp_array\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"sample\",\n",
    "      \"table_names\": [\"sample\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"subject\",\n",
    "      \"table_names\": [\"subject\", \"blood_pressure_test\", \"cardiac_mri\", \"demographic\", \"electrocardiogram_test\", \"exposure\", \"lab_result\", \"medical_history\", \"medication\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"study\",\n",
    "      \"table_names\": [\"study\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"project\",\n",
    "      \"table_names\": [\"project\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"program\",\n",
    "      \"table_names\": [\"program\"]\n",
    "    }\n",
    "  ],\n",
    "  \"final_index_source_column\": \"subject_submitter_id\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_gen3_geno_pheno_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_GENO_PHENO_MERGE_SPEC, new_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a consolidated data table containing only genomic (no phenotypic) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN3_GENO_MERGE_SPEC =  {\n",
    "  \"default_join_type\": \"outer\",\n",
    "  \"merge_sequence\": [\n",
    "    {\n",
    "      \"join_column\": \"simple_germline_variation\",\n",
    "      \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"submitted_aligned_reads\",\n",
    "      \"table_names\": [\"submitted_aligned_reads\", \"aligned_reads_index\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"read_group\",\n",
    "      \"table_names\": [\"read_group\", \"submitted_unaligned_reads\", \"read_group_qc\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"aliquot\",\n",
    "      \"table_names\": [\"aliquot\", \"submitted_cnv_array\", \"submitted_snp_array\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"sample\",\n",
    "      \"table_names\": [\"sample\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"subject\",\n",
    "      \"table_names\": [\"subject\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"study\",\n",
    "      \"table_names\": [\"study\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"project\",\n",
    "      \"table_names\": [\"project\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"program\",\n",
    "      \"table_names\": [\"program\"]\n",
    "    }\n",
    "  ],\n",
    "  \"final_index_source_column\": \"subject_submitter_id\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_gen3_geno_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_GENO_MERGE_SPEC, new_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a consolidated data table containing only phenotypic (not genomic) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here the \"sample\" table is being included in the phenotypic data because it contains useful identifier information (e.g., the \"NWD\" identifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN3_PHENO_MERGE_SPEC =  {\n",
    "  \"default_join_type\": \"left\",\n",
    "  \"merge_sequence\": [\n",
    "    {\n",
    "      \"join_column\": \"subject\",\n",
    "      \"table_names\": [\"subject\", \"sample\", \"blood_pressure_test\", \"cardiac_mri\", \"demographic\", \"electrocardiogram_test\", \"exposure\", \"lab_result\", \"medical_history\", \"medication\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"study\",\n",
    "      \"table_names\": [\"study\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"project\",\n",
    "      \"table_names\": [\"project\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"program\",\n",
    "      \"table_names\": [\"program\"]\n",
    "    }\n",
    "  ],\n",
    "  \"final_index_source_column\": \"subject_submitter_id\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_gen3_pheno_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_PHENO_MERGE_SPEC, new_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Merge Specification and Use\n",
    "\n",
    "TODO - Information about customizing merge specifications is needed, and will likely be fairly volumonous. This may be best placed in a repo readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN3_USER_CUSTOM_MERGE_SPEC =  {\n",
    "  \"default_join_type\": \"inner\",\n",
    "  \"merge_sequence\": [\n",
    "    {\n",
    "      \"join_column\": \"simple_germline_variation\",\n",
    "      \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"submitted_aligned_reads\",\n",
    "      \"table_names\": [\"submitted_aligned_reads\", \"aligned_reads_index\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"read_group\",\n",
    "      \"table_names\": [\"read_group\", \"submitted_unaligned_reads\", \"read_group_qc\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"aliquot\",\n",
    "      \"table_names\": [\"aliquot\", \"submitted_cnv_array\", \"submitted_snp_array\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"sample\",\n",
    "      \"table_names\": [\"sample\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"subject\",\n",
    "      \"join_type\": \"left\",\n",
    "      \"table_names\": [\"subject\", \"blood_pressure_test\", \"cardiac_mri\", \"demographic\", \"electrocardiogram_test\", \"exposure\", \"lab_result\", \"medical_history\", \"medication\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"study\",\n",
    "      \"table_names\": [\"study\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"project\",\n",
    "      \"table_names\": [\"project\"]\n",
    "    },\n",
    "    {\n",
    "      \"join_column\": \"program\",\n",
    "      \"table_names\": [\"program\"]\n",
    "    }\n",
    "  ],\n",
    "  \"final_index_source_column\": \"subject_submitter_id\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_gen3_custom_tables(new_table_name: str):\n",
    "    consolidate_to_terra_table(GEN3_USER_CUSTOM_MERGE_SPEC, new_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def delete_terra_table(project: str, workspace: str, table_name: str):\n",
    "    if table_name not in DataTableInfo.get_table_names(True):\n",
    "        logger.warning(\"Data table \\\"{}\\\" not found.\".format(table_name))\n",
    "        return\n",
    "    \n",
    "    logger.info(\"Starting deletion of data table \\\"{}\\\". This may require serveral minutes or longer for large tables.\".format(table_name))\n",
    "    # TODO There should be better way than this to simply delete a table/entity-type.\n",
    "    entity_id_column_name = f\"entity:{table_name}_id\"\n",
    "    table_to_delete_df = get_terra_table_to_df(project, workspace, table_name, attributeNames=[entity_id_column_name])\n",
    "    entity_id_series = table_to_delete_df[entity_id_column_name]\n",
    "    num_chunks = entity_id_series.size / 100\n",
    "    sys.stdout.write(\"Deleting \")\n",
    "    for chunk in  np.array_split(entity_id_series, num_chunks):\n",
    "        response = fapi.delete_entity_type(project, workspace, table_name, chunk)\n",
    "        fapi._check_response_code(response, 204)\n",
    "        sys.stdout.write(\".\")\n",
    "    logger.info(\"\\nFinished deleting data table \\\"{}\\\".\".format(table_name))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and functions used internally and not intended for user modification.  \n",
    "*The code in the rest of this document will likely be moved to a new Python library \"soon\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the set of tables defined in the Gen3 data model, for Notebook-internal use.  \n",
    "All of the tables used in merge specications must exist in this set yet this set may contain additional tables names are not used in the merge specifications and do not exist in the current workspace data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN3_TABLE_NAMES={\"aligned_reads_index\",\n",
    "                 \"aliquot\",\n",
    "                 \"blood_pressure_test\",\n",
    "                 \"cardiac_mri\",\n",
    "                 \"demographic\",\n",
    "                 \"electrocardiogram_test\",\n",
    "                 \"exposure\",\n",
    "                 \"germline_variation_index\",\n",
    "                 \"lab_result\",\n",
    "                 \"medical_history\",\n",
    "                 \"medication\",\n",
    "                 \"program\",\n",
    "                 \"project\",\n",
    "                 \"read_group\",\n",
    "                 \"read_group_qc\"\n",
    "                 \"reference_file\",\n",
    "                 \"sample\",\n",
    "                 \"simple_germline_variation\",\n",
    "                 \"study\",\n",
    "                 \"subject\",\n",
    "                 \"submitted_aligned_reads\",\n",
    "                 \"submitted_cnv_array\",\n",
    "                 \"submitted_snp_array\",\n",
    "                 \"submitted_unaligned_reads\"\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if logger.isEnabledFor(DEBUG):\n",
    "    %xmode Verbose\n",
    "    import pysnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_terra_table(merge_spec: dict, entity_name: str)  -> pd.DataFrame:\n",
    "    \n",
    "    if 'final_index_source_column' in merge_spec and len(merge_spec['final_index_source_column']):\n",
    "        entity_id_column = merge_spec['final_index_source_column']\n",
    "    else:\n",
    "        logger.error(\"The merge specification field \\\"final_index_source_column\\\" is missing or has an empty value.\")\n",
    "        return\n",
    "    \n",
    "    # Check for an existing table with the same name and log accordingly\n",
    "    if (entity_name in DataTableInfo.get_table_names()):\n",
    "        existing_rows, existing_columns, _ = DataTableInfo.get_table_info(entity_name)\n",
    "        logger.info(\"A data table with the name \\\"{}\\\" already exists with dimmesions ({}x{}). Corresponding data will be updated and any existing additional data will be left unchanged.\".format(\n",
    "        entity_name, existing_rows, existing_columns))\n",
    "    \n",
    "    consolidated_df = consolidate_to_df(merge_spec)\n",
    " \n",
    "    # Add \"entity:{entity_name}_id\" as the first column, as required by Terra.\n",
    "    consolidated_df.insert(0, f\"entity:{entity_name}_id\", consolidated_df[entity_id_column])\n",
    "    \n",
    "    consolidated_df_rows, consolidated_df_columns = consolidated_df.shape\n",
    "    if logger.isEnabledFor(DEBUG):\n",
    "        logger.info(\"The in-memory consolidated data frame size is: {} rows x {} columns\".format(consolidated_df.shape[0], consolidated_df.shape[1]))\n",
    "        write_df_to_tsv_file(consolidated_df, \"consolidated_df\")\n",
    "    \n",
    "    upload_entities_df(consolidated_df)\n",
    "    \n",
    "    # Compare the in-memory and actual uploaded data table sizes and output the results.\n",
    "    actual_rows, actual_columns, _ = DataTableInfo.get_table_info(entity_name, True)\n",
    "    if (consolidated_df_rows == actual_rows and consolidated_df_columns == actual_columns):\n",
    "        logger.info(\"The consolidated data table \\\"{}\\\" size is: {} rows x {} columns\".format(\n",
    "            entity_name, actual_rows, actual_columns))\n",
    "    else:\n",
    "        if (consolidated_df_rows > actual_rows or consolidated_df_columns > actual_columns):\n",
    "            logger.error(\"Data table truncation error.\"\n",
    "                         \" The in-memory consolidated data table has more rows or columns ({}x{}) than the data table \\\"{}\\\" uploaded to Terra ({}x{})\".format(\n",
    "                           entity_name, consolidated_df_rows, consolidated_df_columns, actual_rows, actual_columns))\n",
    "        else:\n",
    "            logger.warning(\"Data table size mismatch warning.\"\n",
    "                           \" The in-memory consolidated data table has fewer rows or columns ({}x{}) than the data \\\"{}\\\" table uploaded to Terra ({}x{})\".format(\n",
    "                           entity_name, consolidated_df_rows, consolidated_df_columns, actual_rows, actual_columns)) \n",
    "            \n",
    "    if logger.isEnabledFor(DEBUG):\n",
    "        all_tables_info = json.dumps(DataTableInfo.get_data_table_info(), indent=4)\n",
    "        logger.debug(\"All table info: {}\".format(all_tables_info))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_tsv(merge_spec: dict)  -> pd.DataFrame:\n",
    "    return consolidate_to_df(merge_spec).to_csv(sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# @pysnooper.snoop\n",
    "def consolidate_to_df(merge_spec: dict)  -> pd.DataFrame:\n",
    "    default_merge_parameters = merge_spec['default_merge_parameters'] if 'default_merge_parameters' in merge_spec else dict(how=\"outer\")\n",
    "    if \"default_join_type\" in merge_spec:\n",
    "        default_merge_parameters['how'] = merge_spec['default_join_type']\n",
    "        \n",
    "    merged_df = None\n",
    "    for merge_info in merge_spec['merge_sequence']:\n",
    "        merge_parameters = _create_combined_merge_parameters(default_merge_parameters, merge_info)\n",
    "        _substitute_entity_id_column_name(merge_parameters)\n",
    "        merged_df = consolidate_tables_to_df(merge_info['table_names'], merge_parameters, merged_df)\n",
    "    return merged_df\n",
    "\n",
    "def _create_combined_merge_parameters(default_merge_parameters: dict, merge_info: dict) -> dict:\n",
    "    standard_pandas_default_parameters = dict(how=\"inner\", on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(\"_x\", \"_y\"), copy=True, indicator=False, validate=None)\n",
    "    combined_parameters = standard_pandas_default_parameters.copy()\n",
    "    combined_parameters.update(default_merge_parameters)\n",
    "    if 'merge_parameters' in merge_info:\n",
    "        combined_parameters.update(merge_info['merge_parameters'])\n",
    "    if 'join_column' in merge_info:\n",
    "        combined_parameters['on'] = merge_info['join_column']\n",
    "    if 'join_type' in merge_info:\n",
    "        combined_parameters['how'] = merge_info['join_type']\n",
    "    return combined_parameters\n",
    "\n",
    "def _substitute_entity_id_column_name(merge_parameters: dict) -> dict:\n",
    "    for key in 'on', 'left_on', 'right_on':\n",
    "        if key in merge_parameters and merge_parameters[key]:\n",
    "            merge_parameters[key] = get_entity_id_column_name(merge_parameters[key])\n",
    "            # TODO - Add support for case where value is a list/array - requires careful testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# @pysnooper.snoop()\n",
    "def consolidate_tables_to_df(table_names: list, merge_parameters: dict, initial_df = None) -> pd.DataFrame:\n",
    "    if initial_df is None:\n",
    "        assert len(table_names) >= 2, \"At least two table names are required.\" \n",
    "        table_name = table_names[0]\n",
    "        table_names = table_names[1:]\n",
    "        first_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        if table_name == \"sample\":\n",
    "            _deduplicate_merge_data(None, first_df, \"sample\", get_entity_id_column_name(\"subject\"))\n",
    "        merged_df = first_df\n",
    "    else:\n",
    "        assert len(table_names) >= 1, \"At least one table names is required to merge with previous data.\"\n",
    "        merged_df = initial_df\n",
    "        \n",
    "    for table_name in table_names:\n",
    "        if table_name not in DataTableInfo.get_table_names():\n",
    "            logger.info(\"The specified table \\\"{}\\\" was not found in this workspace and will be ignored.\".format(table_name))\n",
    "            continue            \n",
    "        current_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        if table_name == \"sample\":\n",
    "            _deduplicate_merge_data(merged_df, current_df, \"sample\", get_entity_id_column_name(\"subject\"))\n",
    "            \n",
    "        if logger.isEnabledFor(DEBUG):\n",
    "            write_df_to_tsv_file(merged_df, \"merged_df\")\n",
    "            write_df_to_tsv_file(current_df, \"current_df\")\n",
    "            \n",
    "        logger.debug(\"Merging table \\\"{}\\\" using column \\\"{}\\\" with join type: {}\".format(\n",
    "            table_name, merge_parameters['on'], merge_parameters['how']))\n",
    "        logger.debug(\"Full merge parameters: {}\".format(merge_parameters))\n",
    "        \n",
    "        merged_df = merged_df.merge(current_df, **merge_parameters)\n",
    "        \n",
    "        # Deduplicate \"*_entity_id\" columns\n",
    "        merged_df = merged_df.loc[:,~merged_df.columns.duplicated()]\n",
    "        \n",
    "        logger.info(\"Merged table \\\"{}\\\" using column \\\"{}\\\" with join type: \\\"{}\\\". New merged table dimmensions: ({}x{})\".format(\n",
    "            table_name, merge_parameters['on'], merge_parameters['how'], merged_df.shape[0], merged_df.shape[1]))\n",
    "        \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deduplicate_merge_data(merged_df: pd.DataFrame, current_df: pd.DataFrame,\n",
    "                           current_table_name: str, current_dedup_key: str) -> None:\n",
    "    # Some TOPMed projects (COPDGene, MESA, maybe others) are known to have multiple sample\n",
    "    # entries for the same subject. According to BioData Catalyst data experts,\n",
    "    # the duplicates should be equivalent, so just keep the first entry found in each case.\n",
    "\n",
    "    # Identify duplicates in the given column of the current table and obtain\n",
    "    # a list of entity ids for the rows containing duplicates.\n",
    "    # Then remove the duplicate rows from the current table.\n",
    "    current_dups = current_df[current_dedup_key].duplicated(keep=\"first\")\n",
    "    current_dups_values = current_df[current_dups][current_dedup_key].tolist()\n",
    "    if len(current_dups_values) == 0:\n",
    "        logger.debug(\"No duplicates found in table {} for key {}\".format(current_table_name, current_dedup_key))\n",
    "        return\n",
    "    current_table_entity_id = get_entity_id_column_name(current_table_name)\n",
    "    common_key_values_for_dupes = current_df[current_dups][current_table_entity_id].tolist()\n",
    "    current_df.drop(current_df[current_dups].index, inplace=True)\n",
    "    logger.warning(\"Removed {} duplicate entries from table \\\"{}\\\" in column \\\"{}\\\". Retained the first entry found. Deleted rows with ids: {}\".format(\n",
    "        len(current_dups_values), current_table_name, current_dedup_key, current_dups_values))\n",
    "\n",
    "    # From the results that have been merged thus far, remove the rows that would have been joined\n",
    "    # to the rows that were deleted as duplicates from the current table. This will prevent \"orphan\"\n",
    "    # rows from being created in the consolidated dataframe, which would otherwise happen with\n",
    "    # some join types (e.g. \"outer\").\n",
    "    if merged_df is not None and current_table_entity_id in merged_df.columns:\n",
    "        mask = merged_df[current_table_entity_id].isin(common_key_values_for_dupes)\n",
    "        merged_df.drop(merged_df[mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gen3_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = get_terra_table_to_df(project, workspace, table_name)\n",
    "    columns = table_df.columns\n",
    "    rename_column(table_df, f\"entity:{table_name}_id\", f\"{table_name}_entity_id\") # Column 0\n",
    "    for column in columns[1:]:\n",
    "        if column in GEN3_TABLE_NAMES:\n",
    "            rename_column(table_df, column, f\"{column}_entity_id\")\n",
    "        else:\n",
    "            rename_column(table_df, column, f\"{table_name}_{column}\")\n",
    "    # Deduplicate \"*_entity_id\" columns\n",
    "    table_df = table_df.loc[:,~table_df.columns.duplicated()]\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_entity_id_column_name(entity_type: str):\n",
    "    return f\"{entity_type}_entity_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO - Move this to the \"Related Convenience Functions\" section above if/when the FireCloudServerError exception handling issue is resolved.\n",
    "\n",
    "def get_terra_table_to_df(project: str, workspace: str, table_name: str, attributeNames=None, model=\"flexible\") -> pd.DataFrame:\n",
    "    response = fapi.get_entities_tsv(project, workspace, table_name, attributeNames, model=model)\n",
    "    if response.status_code != 200:\n",
    "        raise FireCloudServiceException(response.status_code, str(response.content) + \" Error code: \" + str(response.status_code))\n",
    "    \n",
    "    table_df = pd.read_csv(io.StringIO(response.text), sep='\\t')\n",
    "    \n",
    "    # Change the dataframe index from the default numeric index to the the entity id column.\n",
    "    # TODO - Resetting the index below had the unexpected effect of causing the subsequent merge\n",
    "    #        operation to fail due to a key error, even though the intended key was present\n",
    "    #        in both tables. Omit the following until it can be investigated and resolved.\n",
    "    # table_df.set_index(f\"entity:{table_name}_id\", inplace=True)\n",
    "    \n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rename_column(df: pd.DataFrame, current_column_name: str, new_column_name: str) -> None:\n",
    "    df.rename(columns={current_column_name : new_column_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_entities_df(df: pd.DataFrame, chunk_size=500) -> None:\n",
    "    chunk_start = chunk_end = 0\n",
    "    row_count = df.shape[0]\n",
    "    while chunk_start < row_count:\n",
    "        chunk_end = min(chunk_start + chunk_size, row_count)\n",
    "        chunk_df = df.iloc[chunk_start:chunk_end]\n",
    "        chunk_tsv = chunk_df.to_csv(sep=\"\\t\", index=False)\n",
    "        fiss_entity_import(BILLING_PROJECT_ID, WORKSPACE, chunk_tsv, \"flexible\")\n",
    "        chunk_start = chunk_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_df_to_tsv_file(df: pd.DataFrame, filename: str) -> None:\n",
    "    filename += \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S%f\") + \".tsv\"\n",
    "    with open(filename, mode=\"w\") as tsv_file:\n",
    "        tsv_string = df.to_csv(sep=\"\\t\", index=False)\n",
    "        tsv_file.write(tsv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fiss_entity_import(project: str, workspace: str, entity_tsv: str, model: str):\n",
    "    response = fapi.upload_entities(project, workspace, entity_tsv, model)\n",
    "    fapi._check_response_code(response, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTableInfo:\n",
    "    _data_table_info = None\n",
    "    _data_table_names = None\n",
    "\n",
    "    @classmethod\n",
    "    def refresh(cls):\n",
    "        response = fapi.list_entity_types(BILLING_PROJECT_ID, WORKSPACE)\n",
    "        if response.status_code == 200:\n",
    "            cls._data_table_info = json.loads(response.text)\n",
    "            cls._data_table_names = list(cls._data_table_info.keys())\n",
    "        else:\n",
    "            cls._data_table_info = None\n",
    "            cls._data_table_names = None\n",
    "            raise FireCloudServiceException(\n",
    "                \"Failed to get entity types. Error code: {}\".format(\n",
    "                    response.status_code))\n",
    "\n",
    "    @classmethod\n",
    "    def get_data_table_info(cls, refresh=False):\n",
    "        if not cls._data_table_info or refresh:\n",
    "            cls.refresh()\n",
    "        return cls._data_table_info.copy()\n",
    "\n",
    "    @classmethod\n",
    "    def get_table_names(cls, refresh=False):\n",
    "        if not cls._data_table_names or refresh:\n",
    "            cls.refresh()\n",
    "        return cls._data_table_names.copy()\n",
    "\n",
    "    @classmethod\n",
    "    def get_table_info(cls, table_name, refresh=False):\n",
    "        if not cls._data_table_info or refresh:\n",
    "            cls.refresh()\n",
    "        row_count = None\n",
    "        column_count = None\n",
    "        attributes = None\n",
    "        if table_name in cls._data_table_names:\n",
    "            row_count = cls._data_table_info[table_name]['count']\n",
    "            attributes = cls._data_table_info[table_name]['attributeNames'].copy()\n",
    "            column_count = len(attributes) + 1  # Add one for the entity id column\n",
    "        return row_count, column_count, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireCloudServiceException(Exception):\n",
    "    \"\"\" A FireCloud service error occurred.\n",
    "\n",
    "    Attributes:\n",
    "        code (int): HTTP response code indicating error type\n",
    "        message (str): Response content, if present\n",
    "    \"\"\"\n",
    "    def __init__(self, code, message):\n",
    "        self.code = code\n",
    "        self.message = message\n",
    "        Exception.__init__(self, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Test/Debug Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines in the cells below to enable some built-in testing, improved debugging abilities or to serve as a simple stand-alone demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test with data in a different workspace than the one that contains this Notebook,\n",
    "specify remote workspace information below. This enables convenient testing of data\n",
    "for multiple different projects/cohorts using this same Notebook in the current workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_PROJECT'] = os.environ['WORKSPACE_NAMESPACE'] = \"anvil-stage-demo\"\n",
    "# os.environ['WORKSPACE_NAME']=\"mbaumann terra_data_util test COPDGene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set standard names used in this Notebook for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "# WORKSPACE = os.environ['WORKSPACE_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify, create and optionally delete the desired tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_example_consolidated_geno_pheno_table=True\n",
    "# create_example_consolidated_geno_table=True\n",
    "# create_example_consolidated_pheno_table=True\n",
    "# create_example_consolidated_custom_table=True\n",
    "# delete_created_tables=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if create_example_consolidated_geno_pheno_table:\n",
    "#     example_table_name = \"example_consolidated_geno_pheno_table\"\n",
    "#     consolidate_gen3_geno_pheno_tables(example_table_name)\n",
    "#     if delete_created_tables:\n",
    "#          delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if create_example_consolidated_geno_table:\n",
    "#     example_table_name = \"example_consolidated_geno_table\"\n",
    "#     consolidate_gen3_geno_tables(example_table_name)\n",
    "#     if delete_created_tables:\n",
    "#          delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if create_example_consolidated_pheno_table:\n",
    "#     example_table_name = \"example_consolidated_pheno_table\"\n",
    "#     consolidate_gen3_pheno_tables(example_table_name)\n",
    "#     if delete_created_tables:\n",
    "#          delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if create_example_consolidated_custom_table:\n",
    "#     example_table_name = \"example_consolidated_custom_table\"\n",
    "#     consolidate_gen3_custom_tables(example_table_name)\n",
    "#     if delete_created_tables:\n",
    "#          delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all tables\n",
    "# for example_table_name in \"example_consolidated_geno_pheno_table\", \"example_consolidated_geno_table\",\\\n",
    "# \"example_consolidated_pheno_table\", \"example_consolidated_custom_table\":\n",
    "#         try:\n",
    "#             logger.info(\"Deleting: {}\".format(example_table_name))\n",
    "#             delete_terra_table(BILLING_PROJECT_ID, WORKSPACE, example_table_name)\n",
    "#             logger.info(f\"Finished deleting:{}\".format(example_table_name))\n",
    "#         except Exception as ex:\n",
    "#             logger.warning(\"Table {} may not exist.\".format(example_table_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
