{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from firecloud import fiss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test_function():\n",
    "    print(\"Called test_function!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen3 High-Level Configuration and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# The following information could(/should) be obtained from Gen3 (dynamically).\n",
    "# For now, use an explicit list.\n",
    "GEN3_TABLE_NAMES={'aligned_reads_index',\n",
    " 'aliquot',\n",
    " 'blood_pressure_test',\n",
    " 'case',\n",
    " 'demographic',\n",
    " 'exposure',\n",
    " 'germline_variation_index',\n",
    " 'lab_result',\n",
    " 'medical_history',\n",
    " 'medication',\n",
    " 'read_group',\n",
    " 'sample',\n",
    " 'simple_germline_variation',\n",
    " 'submitted_aligned_reads'}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO Identify columns that occur in multiple tables (are are different than the join key columns?)\n",
    "GEN3_COMMON_COLUMNS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "GEN3_GENO_PHENO_MERGE_SPEC = [\n",
    "    {\n",
    "        \"join_key\": \"simple_germline_variation_eid\",\n",
    "        \"table_names\": [\"simple_germline_variation\", \"germline_variation_index\"]\n",
    "    }\n",
    "]\n",
    "# GEN3_ENTITY_ID_COLUMN = \"submitter_id_case\"\n",
    "GEN3_ENTITY_ID_COLUMN = \"simple_germline_variation_eid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# action values: replace, update\n",
    "# TODO Consider making action an Enum\n",
    "def consolidate_gen3_geno_pheno_tables(new_table_name: str, action:str=\"replace\"):\n",
    "    # TODO Implement `action` support\n",
    "    consolidate_to_terra_table(GEN3_GENO_PHENO_MERGE_SPEC, GEN3_ENTITY_ID_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# action values: replace, update\n",
    "def consolidate_gen3_geno_tables(new_table_name: str, action:str =\"replace\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# action values: replace, update\n",
    "def consolidate_gen3_pheno_tables(new_table_name: str, action:str =\"replace\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Mid-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_terra_table(merge_spec: list,  entity_id_column:str)  -> pd.DataFrame:\n",
    "    consolidated_df = consolidate_to_df(merge_spec)\n",
    "    # Add \"entity:{entity_id_column}_id\" as the first column, as required by Terra.\n",
    "    # TODO Check if there is a better way to do this.\n",
    "    entity_id_column_name = f\"entity:{entity_id_column}_id\"\n",
    "    consolidated_df.insert(0, entity_id_column_name, consolidated_df[entity_id_column])\n",
    "    # consolidated_df.set_index(entity_id_column_name, inplace=True)\n",
    "    # columns = consolidated_df.columns.tolist()\n",
    "    # columns = columns[-1:] + columns[:-1]\n",
    "    # consolidated_df = consolidated_df[columns]\n",
    "    columns = consolidated_df.columns.tolist()\n",
    "    write_df_to_tsv_file(consolidated_df, \"consolidated_df\")\n",
    "    consolidated_tsv = consolidated_df.to_csv(sep=\"\\t\", index=False)\n",
    "    fiss_entity_import(BILLING_PROJECT_ID, WORKSPACE, consolidated_tsv, \"flexible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_tsv(merge_spec: list)  -> pd.DataFrame:\n",
    "    return consolidate_to_df(merge_spec).to_csv(sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_to_df(merge_spec: list)  -> pd.DataFrame:\n",
    "    # TODO Need to consolidate df across multiple merge specs\n",
    "    merged_df = None\n",
    "    for merge_info in merge_spec:\n",
    "        merged_df = consolidate_tables_to_df(merge_info['join_key'], merge_info['table_names'], merged_df)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Lower-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_tables_to_terra_table(common_key: str, table_names: list, new_entity_type: str, entity_id_column:str) -> None:\n",
    "    consolidated_df = consolidate_tables_to_df(common_key, table_names)\n",
    "    # Add \"entity:{new_entity_type}_id\" column, as required by Terra\n",
    "    consolidated_df[f\"entity:{new_entity_type}_id\"] = consolidated_df[entity_id_column]\n",
    "    consolidated_tsv = consolidated_df.to_csv(sep=\"\\t\")\n",
    "    fiss_entity_import(BILLING_PROJECT_ID, WORKSPACE, consolidated_tsv, \"flexible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_tables_to_tsv(common_key: str, table_names: list) -> str:\n",
    "    return consolidate_tables_to_df(common_key, table_names).to_csv(sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO Change common name colums to name_tablename before merging\n",
    "# TODO Handle case of \"_id\" \n",
    "def consolidate_tables_to_df(common_key: str, table_names: list, initial_df = None) -> pd.DataFrame:\n",
    "    if initial_df is None:\n",
    "        assert len(table_names) >= 2, \"At least two table names are required.\" \n",
    "        table_name = table_names[0]\n",
    "        merged_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        table_names = table_names[1:]\n",
    "        # if common_key == table_name:\n",
    "        #    rename_column(merged_df, f\"entity:{common_key}_id\", common_key)\n",
    "    else:\n",
    "        assert len(table_names) >= 1, \"At least one table names is required to merge with previous data.\"\n",
    "    for table_name in table_names:\n",
    "        current_df = get_gen3_terra_table_to_df(BILLING_PROJECT_ID, WORKSPACE, table_name)\n",
    "        # DEBUG -- Remove the following two lines before comitting\n",
    "        write_df_to_tsv_file(merged_df, \"merged_df\")\n",
    "        write_df_to_tsv_file(current_df, \"current_df\")\n",
    "        merged_df = merged_df.merge(current_df, on=common_key, how=\"inner\", copy=False, suffixes=(\"\", \"_\"+table_name))\n",
    "        # Deduplicate \"*_eid\" columns\n",
    "        merged_df = merged_df.loc[:,~merged_df.columns.duplicated()]\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Low-Level Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rename_column(df: pd.DataFrame, current_column_name: str, new_column_name: str) -> None:\n",
    "    df.rename(columns={current_column_name : new_column_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# FISS entity_import expects the TSV content to be in a file, yet here it is already\n",
    "# a string and it doesn't make sense to write content to a file only to read it in again.\n",
    "# The data may be large, and FISS entity_import performs chunking, which should be used.\n",
    "# Therefore bypass fiss `entity_import` per se and call `_batch_load` directly.\n",
    "# EntityImportArgs = namedtuple(\"EntityImportArgs\", [\"project\", \"workspace\", \"tsvfile\", \"chunk_size\", \"model\"])\n",
    "def fiss_entity_import_batch_bad(project: str, workspace: str, entity_tsv: str, model: str):\n",
    "    # args = EntityImportArgs(project, workspace, io.StringIO(entity_data), 500, model)\n",
    "    # fiss.entity_import(args)\n",
    "    entity_tsv_filelike = io.StringIO(entity_tsv)\n",
    "    headerline = entity_tsv_filelike.readline().strip()\n",
    "    entity_data = [l.rstrip('\\n') for l in entity_tsv_filelike]\n",
    "    return fiss._batch_load(project, workspace, headerline, entity_data, 500, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fiss_entity_import(project: str, workspace: str, entity_tsv: str, model: str):\n",
    "    r = fiss.fapi.upload_entities(project, workspace, entity_tsv, model)\n",
    "    print(r)\n",
    "    fiss.fapi._check_response_code(r, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_gen3_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = get_terra_table_to_df(project, workspace, table_name)\n",
    "    columns = table_df.columns\n",
    "    rename_column(table_df, f\"entity:{table_name}_id\", f\"{table_name}_eid\") # Column 0\n",
    "    for column in columns[1:]:\n",
    "        if column in GEN3_TABLE_NAMES:\n",
    "            rename_column(table_df, column, f\"{column}_eid\")\n",
    "        else:\n",
    "            rename_column(table_df, column, f\"{table_name}_{column}\")\n",
    "    # Deduplicate \"*_eid\" columns\n",
    "    table_df = table_df.loc[:,~table_df.columns.duplicated()]\n",
    "    return table_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_terra_table_to_df(project: str, workspace: str, table_name: str, model=\"flexible\") -> pd.DataFrame:\n",
    "    table_df = pd.read_csv(io.StringIO(fiss.fapi.get_entities_tsv(project, workspace, table_name, model=model).text), sep='\\t')\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def write_df_to_tsv_file(df: pd.DataFrame, filename: str) -> None:\n",
    "    filename += \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S%f\") + \".tsv\"\n",
    "    with open(filename, mode=\"w\") as tsv_file:\n",
    "        tsv_string = df.to_csv(sep=\"\\t\", index=False)\n",
    "        tsv_file.write(tsv_string)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Test/Debug Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Temporary settings for running in PyCharm\n",
    "os.environ['WORKSPACE_NAMESPACE']=\"anvil-stage-demo\"\n",
    "os.environ['GOOGLE_PROJECT']=os.environ['WORKSPACE_NAMESPACE']\n",
    "os.environ['WORKSPACE_NAME']=\"mbaumann dev fiss debug playground 20190925 2141\"\n",
    "os.environ['WORKSPACE_BUCKET']=\"gs://fc-secure-55824595-dc0f-4b14-b5fb-9d7f9cf662be\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'anvil-stage-demo'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "# Set and verify the Google billing project environment variable\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "BILLING_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'mbaumann dev fiss debug playground 20190925 2141'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "# Set and verify the Workspace name\n",
    "WORKSPACE = os.environ['WORKSPACE_NAME']\n",
    "WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<Response [200]>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# %%pixie_debugger\n",
    "consolidated_table_name = \"my_consolidated_table\"\n",
    "consolidate_gen3_geno_pheno_tables(consolidated_table_name, \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}